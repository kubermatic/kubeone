# generated using below command:
# helm template autoscaler/cluster-autoscaler --version 9.49.0 -n kube-system --name-template cluster-autoscaler \
# --set cloudProvider=clusterapi,fullnameOverride=cluster-autoscaler,additionalLabels.k8s-app=cluster-autoscaler,additionalLabels.k8s-addon=cluster-autoscaler.addons.k8s.io,autoDiscovery.namespace=kube-system,extraEnv.CAPI_GROUP=cluster.k8s.io,"tolerations[0].effect=NoSchedule,tolerations[0].key=node-role.kubernetes.io/control-plane,affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms[0].matchExpressions[0].key=node-role.kubernetes.io/control-plane,affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms[0].matchExpressions[0].operator=Exists" \
# --set-string service.annotations."prometheus\.io/scrape"=true,service.annotations."prometheus\.io/port"=8085 | sed "s/x-k8s/k8s/g" | sed "/managed-by/d"

# Must add/replace these in Deployment in the generated output for upgrades.
        # - image: '{{ default (.InternalImages.Get "ClusterAutoscaler") .Params.CLUSTER_AUTOSCALER_IMAGE }}'
        #   args:
        #     - --skip-nodes-with-local-storage={{ default "true" .Params.CLUSTER_AUTOSCALER_SKIP_LOCAL_STORAGE }}
        #     - --enforce-node-group-min-size={{ default "false" .Params.CLUSTER_AUTOSCALER_ENFORCE_NODE_GROUP_MIN_SIZE }}
        #     - --balance-similar-node-groups={{ default "false" .Params.CLUSTER_AUTOSCALER_BALANCE_SIMILAR_NODE_GROUP }}
        #     - --scale-down-utilization-threshold={{ default "0.5" .Params.CLUSTER_AUTOSCALER_SCALE_DOWN_UTIL_THRESHOLD }}
---
# Source: cluster-autoscaler/templates/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
    helm.sh/chart: "cluster-autoscaler-9.49.0"
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: "cluster-autoscaler"
      app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
  maxUnavailable: 1
---
# Source: cluster-autoscaler/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
    helm.sh/chart: "cluster-autoscaler-9.49.0"
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
automountServiceAccountToken: true
---
# Source: cluster-autoscaler/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
    helm.sh/chart: "cluster-autoscaler-9.49.0"
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
rules:
  - apiGroups:
      - ""
    resources:
      - events
      - endpoints
    verbs:
      - create
      - patch
  - apiGroups:
    - ""
    resources:
    - pods/eviction
    verbs:
    - create
  - apiGroups:
      - ""
    resources:
      - pods/status
    verbs:
      - update
  - apiGroups:
      - ""
    resources:
      - endpoints
    resourceNames:
      - cluster-autoscaler
    verbs:
      - get
      - update
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
    - watch
    - list
    - create
    - delete
    - get
    - update
  - apiGroups:
    - ""
    resources:
      - namespaces
      - pods
      - services
      - replicationcontrollers
      - persistentvolumeclaims
      - persistentvolumes
    verbs:
      - watch
      - list
      - get
  - apiGroups:
    - batch
    resources:
      - jobs
      - cronjobs
    verbs:
      - watch
      - list
      - get
  - apiGroups:
    - batch
    - extensions
    resources:
    - jobs
    verbs:
    - get
    - list
    - patch
    - watch
  - apiGroups:
      - extensions
    resources:
      - replicasets
      - daemonsets
    verbs:
      - watch
      - list
      - get
  - apiGroups:
      - policy
    resources:
      - poddisruptionbudgets
    verbs:
      - watch
      - list
  - apiGroups:
    - apps
    resources:
    - daemonsets
    - replicasets
    - statefulsets
    verbs:
    - watch
    - list
    - get
  - apiGroups:
    - storage.k8s.io
    resources:
    - storageclasses
    - csinodes
    - csidrivers
    - csistoragecapacities
    - volumeattachments
    verbs:
    - watch
    - list
    - get
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - list
      - watch
      - get
  - apiGroups:
    - coordination.k8s.io
    resources:
    - leases
    verbs:
    - create
  - apiGroups:
    - coordination.k8s.io
    resourceNames:
    - cluster-autoscaler
    resources:
    - leases
    verbs:
    - get
    - update
  - apiGroups:
    - cluster.k8s.io
    resources:
    - machinedeployments
    - machinepools
    - machines
    - machinesets
    verbs:
    - get
    - list
    - update
    - watch
  - apiGroups:
    - cluster.k8s.io
    resources:
    - machinedeployments/scale
    - machinepools/scale
    verbs:
    - get
    - patch
    - update
---
# Source: cluster-autoscaler/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
    helm.sh/chart: "cluster-autoscaler-9.49.0"
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-autoscaler
    namespace: kube-system
---
# Source: cluster-autoscaler/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
    helm.sh/chart: "cluster-autoscaler-9.49.0"
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - create
  - apiGroups:
      - ""
    resources:
      - configmaps
    resourceNames:
      - cluster-autoscaler-status
    verbs:
      - delete
      - get
      - update
---
# Source: cluster-autoscaler/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
    helm.sh/chart: "cluster-autoscaler-9.49.0"
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: cluster-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-autoscaler
    namespace: kube-system
---
# Source: cluster-autoscaler/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/port: "8085"
    prometheus.io/scrape: "true"
  labels:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
    helm.sh/chart: "cluster-autoscaler-9.49.0"
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
spec:
  ports:
    - port: 8085
      protocol: TCP
      targetPort: 8085
      name: http
  selector:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
  type: "ClusterIP"
---
# Source: cluster-autoscaler/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    {}
  labels:
    app.kubernetes.io/instance: "cluster-autoscaler"
    app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
    helm.sh/chart: "cluster-autoscaler-9.49.0"
    k8s-addon: cluster-autoscaler.addons.k8s.io
    k8s-app: cluster-autoscaler
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: "cluster-autoscaler"
      app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: "cluster-autoscaler"
        app.kubernetes.io/name: "clusterapi-cluster-autoscaler"
        k8s-addon: cluster-autoscaler.addons.k8s.io
        k8s-app: cluster-autoscaler
    spec:
      priorityClassName: "system-cluster-critical"
      dnsPolicy: "ClusterFirst"
      containers:
        - name: clusterapi-cluster-autoscaler
        - image: '{{ default (.InternalImages.Get "ClusterAutoscaler") .Params.CLUSTER_AUTOSCALER_IMAGE }}'
          imagePullPolicy: "IfNotPresent"
          command:
            - ./cluster-autoscaler
            - --cloud-provider=clusterapi
            - --namespace=kube-system
            - --node-group-auto-discovery=clusterapi:namespace=kube-system
            - --logtostderr=true
            - --stderrthreshold=info
            - --v=4
            - --skip-nodes-with-local-storage={{ default "true" .Params.CLUSTER_AUTOSCALER_SKIP_LOCAL_STORAGE }}
            - --enforce-node-group-min-size={{ default "false" .Params.CLUSTER_AUTOSCALER_ENFORCE_NODE_GROUP_MIN_SIZE }}
            - --balance-similar-node-groups={{ default "false" .Params.CLUSTER_AUTOSCALER_BALANCE_SIMILAR_NODE_GROUP }}
            - --scale-down-utilization-threshold={{ default "0.5" .Params.CLUSTER_AUTOSCALER_SCALE_DOWN_UTIL_THRESHOLD }}
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: SERVICE_ACCOUNT
              valueFrom:
                fieldRef:
                  fieldPath: spec.serviceAccountName
            - name: CAPI_GROUP
              value: "cluster.k8s.io"
          livenessProbe:
            httpGet:
              path: /health-check
              port: 8085
          ports:
            - containerPort: 8085
          resources:
            {}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
      serviceAccountName: cluster-autoscaler
      tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
